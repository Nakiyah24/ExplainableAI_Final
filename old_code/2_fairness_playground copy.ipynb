{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a253b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import random\n",
    "import joblib\n",
    "import pathlib\n",
    "import shap\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926638aa",
   "metadata": {},
   "source": [
    "## Step 1 — Load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "451d2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load path and get all the required files\n",
    "def get_paths(base=\"fairness_artifacts\"):\n",
    "    base = pathlib.Path(base)\n",
    "    return {\n",
    "        \"X_train\": base / \"X_train.parquet\",\n",
    "        \"X_test\": base / \"X_test.parquet\",\n",
    "        \"y_train\": base / \"y_train.parquet\",\n",
    "        \"y_test\": base / \"y_test.parquet\",\n",
    "        \"df_meta\": base / \"df_meta.parquet\",\n",
    "        \"ids_test\": base / \"ids_test.parquet\",\n",
    "        \"model\": base / \"final_lightgbm_model.pkl\",\n",
    "    }\n",
    "\n",
    "\n",
    "def load_artifacts(base=\"fairness_artifacts\"):\n",
    "    paths = get_paths(base)\n",
    "\n",
    "    X_train = pd.read_parquet(paths[\"X_train\"])\n",
    "    X_test = pd.read_parquet(paths[\"X_test\"])\n",
    "    y_train = pd.read_parquet(paths[\"y_train\"])[\"hospitalized\"]\n",
    "    y_test = pd.read_parquet(paths[\"y_test\"])[\"hospitalized\"]\n",
    "    df_meta = pd.read_parquet(paths[\"df_meta\"])\n",
    "    ids_test = pd.read_parquet(paths[\"ids_test\"])[\"person_id\"]\n",
    "    model = joblib.load(paths[\"model\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, df_meta, ids_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d6c59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, df_meta, ids_test, final_lgb = load_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7308add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "X Train: (15135, 65)\n",
      "X Test: (3784, 65)\n",
      "y Train: (15135,)\n",
      "y Test: (3784,)\n",
      "ids_test: (3784,)\n",
      "df_meta: (18919, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\")\n",
    "print(\"X Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"y Train:\", y_train.shape)\n",
    "print(\"y Test:\", y_test.shape)\n",
    "print(\"ids_test:\", ids_test.shape)\n",
    "print(\"df_meta:\", df_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ea49d",
   "metadata": {},
   "source": [
    "## Step 2 — Build base evaluation table\n",
    "\n",
    "For the fairness playground, I need a clean table that captures what the model actually did on the test set. Thus, I will now build a base evaluation table on the test set that includes person_id, the true label, the predicted probability, and the final 0/1 prediction. This is the core model-output layer I’ll use when joining with demographics and computing group-wise fairness metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd18a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_eval_table(X_test, y_test, ids_test, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Build a base evaluation table on the test set.\n",
    "    \"\"\"\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "\n",
    "    df_eval = pd.DataFrame(\n",
    "        {\n",
    "            \"person_id\": ids_test.values,\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_pred_proba\": proba,\n",
    "            \"y_pred\": y_pred,\n",
    "        }\n",
    "    )\n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786bf732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "person_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y_true",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y_pred_proba",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_pred",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5cfdfe93-8857-4d85-9e0b-405840637a60",
       "rows": [
        [
         "0",
         "2795536102",
         "0",
         "0.0001254021416326357",
         "0"
        ],
        [
         "1",
         "2796668104",
         "0",
         "0.0006086147803528091",
         "0"
        ],
        [
         "2",
         "2815945102",
         "0",
         "0.00019582131977874826",
         "0"
        ],
        [
         "3",
         "2813232102",
         "0",
         "0.0023058245286689746",
         "0"
        ],
        [
         "4",
         "2810968102",
         "0",
         "0.0003525557074554451",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2795536102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2796668104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2815945102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2813232102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2810968102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_id  y_true  y_pred_proba  y_pred\n",
       "0  2795536102       0      0.000125       0\n",
       "1  2796668104       0      0.000609       0\n",
       "2  2815945102       0      0.000196       0\n",
       "3  2813232102       0      0.002306       0\n",
       "4  2810968102       0      0.000353       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval = make_base_eval_table(X_test, y_test, ids_test, final_lgb)\n",
    "display(df_eval.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c5876",
   "metadata": {},
   "source": [
    "### Step 3 — Merge with demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc75094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_eval_and_meta(df_eval, df_meta):\n",
    "    df_merged = df_eval.merge(df_meta, on=\"person_id\", how=\"left\")\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bebe44a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    person_id  y_true  y_pred_proba  y_pred  age  sex  race_ethnicity  \\\n",
      "0  2795536102       0      0.000125       0   44    1               2   \n",
      "1  2796668104       0      0.000609       0    4    1               1   \n",
      "2  2815945102       0      0.000196       0   60    2               1   \n",
      "3  2813232102       0      0.002306       0   59    1               2   \n",
      "4  2810968102       0      0.000353       0   30    1               2   \n",
      "\n",
      "   hispanic  poverty_category  insurance_coverage  family_income  \\\n",
      "0         2                 4                   1         142202   \n",
      "1         1                 1                   2              0   \n",
      "2         1                 4                   3          64010   \n",
      "3         2                 5                   1         335489   \n",
      "4         2                 4                   3          47840   \n",
      "\n",
      "   self_rated_health  self_rated_mental_health  \n",
      "0                2.0                       2.0  \n",
      "1                4.0                       3.0  \n",
      "2                4.0                       3.0  \n",
      "3                2.0                       2.0  \n",
      "4                1.0                       2.0  \n"
     ]
    }
   ],
   "source": [
    "# merge model outputs with demographics\n",
    "df_fair = merge_eval_and_meta(df_eval, df_meta)\n",
    "print(df_fair.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6bc23e",
   "metadata": {},
   "source": [
    "### Step 4: Recoding demographic columns with human-readable labels\n",
    "\n",
    "The demographic variables in MEPS are all encoded as numbers, so before I can compute fairness metrics or show any results in the playground, I need them in human-readable form. This step converts all the MEPS-coded fields — sex, race/ethnicity, Hispanic status, poverty category, insurance coverage, and self-rated health — into clear labels. This makes the fairness results interpretable and avoids exposing raw codes in the playground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b57109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode sex\n",
    "def recode_sex(df):\n",
    "    sex_map = {1: \"Male\", 2: \"Female\"}\n",
    "    df[\"sex\"] = df[\"sex\"].map(sex_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Recode Race/Ethnicity (RACETHX)\n",
    "def recode_race_ethnicity(df):\n",
    "    race_map = {\n",
    "        1: \"Hispanic\",\n",
    "        2: \"White\",\n",
    "        3: \"Black\",\n",
    "        4: \"Asian\",\n",
    "        5: \"Other OR Multiple\",\n",
    "    }\n",
    "    df[\"race_ethnicity\"] = df[\"race_ethnicity\"].map(race_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Recode Hispanic Flag (HISPANX)\n",
    "def recode_hispanic(df):\n",
    "    hisp_map = {1: \"Hispanic\", 2: \"Not Hispanic\"}\n",
    "    df[\"hispanic\"] = df[\"hispanic\"].map(hisp_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Poverty Category (POVCAT23)\n",
    "def recode_poverty(df):\n",
    "    pov_map = {\n",
    "        1: \"Poor OR negative\",\n",
    "        2: \"Low income\",\n",
    "        3: \"Middle income\",\n",
    "        4: \"High income\",\n",
    "        5: \"Unclassifiable\",\n",
    "    }\n",
    "    df[\"poverty_category\"] = df[\"poverty_category\"].map(pov_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Insurance Coverage (INSCOV23)\n",
    "def recode_insurance(df):\n",
    "    ins_map = {1: \"Any private\", 2: \"Public only\", 3: \"Uninsured\"}\n",
    "    df[\"insurance_coverage\"] = df[\"insurance_coverage\"].map(ins_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Recode Self-Rated Health (RTHLTH53)\n",
    "def recode_self_rated_health(df):\n",
    "    health_map = {\n",
    "        1: \"Excellent\",\n",
    "        2: \"Very good\",\n",
    "        3: \"Good\",\n",
    "        4: \"Fair\",\n",
    "        5: \"Poor\",\n",
    "    }\n",
    "    df[\"self_rated_health\"] = (\n",
    "        df[\"self_rated_health\"].round().astype(\"Int64\").map(health_map)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Recode Self-Rated Mental Health (MNHLTH53)\n",
    "def recode_self_rated_mental(df):\n",
    "    mental_map = {\n",
    "        1: \"Excellent\",\n",
    "        2: \"Very good\",\n",
    "        3: \"Good\",\n",
    "        4: \"Fair\",\n",
    "        5: \"Poor\",\n",
    "    }\n",
    "    df[\"self_rated_mental_health\"] = (\n",
    "        df[\"self_rated_mental_health\"].round().astype(\"Int64\").map(mental_map)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply all recodings\n",
    "def apply_all_recodings(df):\n",
    "    return (\n",
    "        df.pipe(recode_sex)\n",
    "        .pipe(recode_race_ethnicity)\n",
    "        .pipe(recode_hispanic)\n",
    "        .pipe(recode_poverty)\n",
    "        .pipe(recode_insurance)\n",
    "        .pipe(recode_self_rated_health)\n",
    "        .pipe(recode_self_rated_mental)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb4ee332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    person_id  y_true  y_pred_proba  y_pred  age     sex race_ethnicity  \\\n",
      "0  2795536102       0      0.000125       0   44    Male          White   \n",
      "1  2796668104       0      0.000609       0    4    Male       Hispanic   \n",
      "2  2815945102       0      0.000196       0   60  Female       Hispanic   \n",
      "3  2813232102       0      0.002306       0   59    Male          White   \n",
      "4  2810968102       0      0.000353       0   30    Male          White   \n",
      "\n",
      "       hispanic  poverty_category insurance_coverage  family_income  \\\n",
      "0  Not Hispanic       High income        Any private         142202   \n",
      "1      Hispanic  Poor OR negative        Public only              0   \n",
      "2      Hispanic       High income          Uninsured          64010   \n",
      "3  Not Hispanic    Unclassifiable        Any private         335489   \n",
      "4  Not Hispanic       High income          Uninsured          47840   \n",
      "\n",
      "  self_rated_health self_rated_mental_health  \n",
      "0         Very good                Very good  \n",
      "1              Fair                     Good  \n",
      "2              Fair                     Good  \n",
      "3         Very good                Very good  \n",
      "4         Excellent                Very good  \n"
     ]
    }
   ],
   "source": [
    "df_fair = apply_all_recodings(df_fair)\n",
    "print(df_fair.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfa1b1",
   "metadata": {},
   "source": [
    "### Step 5: Group level fairness Metrics\n",
    "\n",
    "Now that the fairness dataset is fully assembled, the next step is to compute standard group-level performance metrics. This helps quantify how the model behaves for different demographic groups. For example, I can compare recall, false negative rate, or positive prediction rate across race, sex, or income levels. These metrics form the backbone of the fairness playground and make it easy to see where the model treats groups differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04400f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_metrics(df, group_col):\n",
    "    \"\"\"\n",
    "    Compute standard model performance metrics for each demographic group.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for group, g in df.groupby(group_col):\n",
    "        y_true = g[\"y_true\"]\n",
    "        y_pred = g[\"y_pred\"]\n",
    "\n",
    "        # Core metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        # Derived metrics\n",
    "        fnr = 1 - rec\n",
    "        fpr = ((y_pred.eq(1) & y_true.eq(0)).sum()) / max((y_true == 0).sum(), 1)\n",
    "        pos_rate = y_pred.mean()\n",
    "        avg_proba = g[\"y_pred_proba\"].mean()\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                group_col: group,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"false_negative_rate\": fnr,\n",
    "                \"false_positive_rate\": fpr,\n",
    "                \"positive_prediction_rate\": pos_rate,\n",
    "                \"avg_pred_probability\": avg_proba,\n",
    "                \"count\": len(g),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f478996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each demographic group\n",
    "race_metrics = compute_group_metrics(df_fair, \"race_ethnicity\")\n",
    "sex_metrics = compute_group_metrics(df_fair, \"sex\")\n",
    "poverty_metrics = compute_group_metrics(df_fair, \"poverty_category\")\n",
    "insurance_metrics = compute_group_metrics(df_fair, \"insurance_coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285268eb",
   "metadata": {},
   "source": [
    "### Step 6 - Disparity Gap Metrics\n",
    "\n",
    "Group metrics tell me how the model performs within each demographic group, but they don’t directly show how far apart the groups are. In this step, I compute simple disparity metrics by picking a reference group and measuring gaps in key quantities like positive prediction rate, recall, and false negative rate. These gaps are what the fairness playground will display when highlighting where the model is more or less sensitive for different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_disparities(group_df, group_col, reference_group=None):\n",
    "    \"\"\"\n",
    "    Compute gaps in metrics versus a reference group.\n",
    "    If reference_group is None, uses the group with the largest count.\n",
    "    \"\"\"\n",
    "    df = group_df.copy()\n",
    "\n",
    "    # Choose reference\n",
    "    if reference_group is None:\n",
    "        reference_group = df.sort_values(\"count\", ascending=False)[group_col].iloc[0]\n",
    "\n",
    "    ref_row = df[df[group_col] == reference_group].iloc[0]\n",
    "\n",
    "    # Metrics we want gaps for\n",
    "    gap_metrics = [\n",
    "        \"positive_prediction_rate\",\n",
    "        \"recall\",\n",
    "        \"precision\",\n",
    "        \"false_negative_rate\",\n",
    "        \"false_positive_rate\",\n",
    "    ]\n",
    "\n",
    "    for m in gap_metrics:\n",
    "        gap_col = f\"{m}_gap_vs_ref\"\n",
    "        df[gap_col] = df[m] - ref_row[m]\n",
    "\n",
    "    df[\"reference_group\"] = reference_group\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute disparities (gaps) for each demographic\n",
    "race_disparities = compute_disparities(race_metrics, \"race_ethnicity\")\n",
    "sex_disparities = compute_disparities(sex_metrics, \"sex\")\n",
    "poverty_disparities = compute_disparities(poverty_metrics, \"poverty_category\")\n",
    "insurance_disparities = compute_disparities(insurance_metrics, \"insurance_coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f612415",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 88\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     74\u001b[0m         df\u001b[38;5;241m.\u001b[39mpipe(recode_sex)\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(recode_race_ethnicity)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(recode_self_rated_mental)\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# CELL 10: Apply Recodings\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m df_fair \u001b[38;5;241m=\u001b[39m apply_all_recodings(\u001b[43mdf_fair\u001b[49m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_fair\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# CELL 11: Group Metrics Function\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_fair' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_global_shap(model, X_test):\n",
    "    \"\"\"\n",
    "    Compute SHAP values for the LightGBM model on the test set.\n",
    "    Returns explainer and properly formatted SHAP values.\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "\n",
    "    # Get SHAP values - LightGBM returns a list for binary classification\n",
    "    shap_values_raw = explainer.shap_values(X_test)\n",
    "\n",
    "    # Handle the list format - extract class 1 (hospitalized)\n",
    "    if isinstance(shap_values_raw, list):\n",
    "        shap_values = shap_values_raw[1]  # Positive class\n",
    "    else:\n",
    "        shap_values = shap_values_raw\n",
    "\n",
    "    # Verify shape\n",
    "    expected_shape = (len(X_test), len(X_test.columns))\n",
    "    actual_shape = shap_values.shape\n",
    "\n",
    "    print(f\"Expected SHAP shape: {expected_shape}\")\n",
    "    print(f\"Actual SHAP shape: {actual_shape}\")\n",
    "\n",
    "    if actual_shape != expected_shape:\n",
    "        raise ValueError(\n",
    "            f\"SHAP values shape mismatch! Expected {expected_shape}, got {actual_shape}\"\n",
    "        )\n",
    "\n",
    "    return explainer, shap_values\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 16: Compute SHAP Values\n",
    "# ============================================================================\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer, shap_values_test = compute_global_shap(final_lgb, X_test)\n",
    "print(\"✓ SHAP computation successful\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 17: Global SHAP Importance Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def global_shap_importance(shap_values, feature_names, top_n=15):\n",
    "    \"\"\"\n",
    "    Calculate global feature importance from SHAP values.\n",
    "    \"\"\"\n",
    "    mean_abs = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    df_imp = (\n",
    "        pd.DataFrame({\"feature\": feature_names, \"mean_abs_shap\": mean_abs})\n",
    "        .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "        .head(top_n)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df_imp\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 18: Compute Global Importance\n",
    "# ============================================================================\n",
    "\n",
    "# Compute and display global importance\n",
    "global_importance = global_shap_importance(shap_values_test, X_test.columns, top_n=15)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 15 MOST IMPORTANT FEATURES (GLOBAL)\")\n",
    "print(\"=\" * 70)\n",
    "print(global_importance.to_string(index=False))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 19: Attach SHAP to DataFrame Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def attach_shap_to_df(df_fair, shap_values, feature_names):\n",
    "    \"\"\"\n",
    "    Attach SHAP values to the fairness dataframe.\n",
    "    \"\"\"\n",
    "    # Verify shapes match\n",
    "    if len(df_fair) != shap_values.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Length mismatch: df_fair has {len(df_fair)} rows, \"\n",
    "            f\"but shap_values has {shap_values.shape[0]} rows\"\n",
    "        )\n",
    "\n",
    "    if len(feature_names) != shap_values.shape[1]:\n",
    "        raise ValueError(\n",
    "            f\"Feature mismatch: {len(feature_names)} feature names provided, \"\n",
    "            f\"but shap_values has {shap_values.shape[1]} columns\"\n",
    "        )\n",
    "\n",
    "    # Create SHAP dataframe with proper shape\n",
    "    shap_df = pd.DataFrame(\n",
    "        shap_values, columns=[f\"shap_{col}\" for col in feature_names]\n",
    "    )\n",
    "\n",
    "    # Add person_id for merging\n",
    "    shap_df[\"person_id\"] = df_fair[\"person_id\"].values\n",
    "\n",
    "    # Merge with original dataframe\n",
    "    df_with_shap = df_fair.merge(shap_df, on=\"person_id\", how=\"left\")\n",
    "\n",
    "    print(f\"Successfully attached {shap_values.shape[1]} SHAP features\")\n",
    "    print(f\"Final shape: {df_with_shap.shape}\")\n",
    "\n",
    "    return df_with_shap\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 20: Attach SHAP Values\n",
    "# ============================================================================\n",
    "\n",
    "# Attach SHAP values to fairness dataframe\n",
    "df_fair_shap = attach_shap_to_df(df_fair, shap_values_test, X_test.columns)\n",
    "print(\"✓ SHAP values attached to dataframe\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample of data with SHAP values:\")\n",
    "shap_cols = [col for col in df_fair_shap.columns if col.startswith(\"shap_\")]\n",
    "print(df_fair_shap[[\"person_id\", \"y_pred_proba\"] + shap_cols[:3]].head())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 21: Group SHAP Importance Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def group_shap_importance(df_with_shap, group_col, feature_names, top_n=10):\n",
    "    \"\"\"\n",
    "    Compute SHAP-based feature importance for each demographic group.\n",
    "    \"\"\"\n",
    "    # Get SHAP column names\n",
    "    shap_cols = [f\"shap_{col}\" for col in feature_names]\n",
    "\n",
    "    # Verify all SHAP columns exist\n",
    "    missing = [col for col in shap_cols if col not in df_with_shap.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing SHAP columns: {missing[:5]}...\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for group, g in df_with_shap.groupby(group_col):\n",
    "        # Calculate mean absolute SHAP for this group\n",
    "        avg_abs = g[shap_cols].abs().mean()\n",
    "\n",
    "        # Remove 'shap_' prefix for cleaner display\n",
    "        avg_abs.index = [col.replace(\"shap_\", \"\") for col in avg_abs.index]\n",
    "\n",
    "        # Sort and get top N\n",
    "        top_features = avg_abs.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "        results[group] = top_features\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 22: Compute Group SHAP Importance\n",
    "# ============================================================================\n",
    "\n",
    "# Compute group-level SHAP importance\n",
    "race_shap = group_shap_importance(df_fair_shap, \"race_ethnicity\", X_test.columns)\n",
    "sex_shap = group_shap_importance(df_fair_shap, \"sex\", X_test.columns)\n",
    "poverty_shap = group_shap_importance(df_fair_shap, \"poverty_category\", X_test.columns)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SHAP FEATURE IMPORTANCE BY RACE/ETHNICITY\")\n",
    "print(\"=\" * 70)\n",
    "for group, importance in race_shap.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    print(importance.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SHAP FEATURE IMPORTANCE BY SEX\")\n",
    "print(\"=\" * 70)\n",
    "for group, importance in sex_shap.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    print(importance.to_string())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 23: Compare Group Feature Importance Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def compare_group_feature_importance(group_shap_dict, top_k=5):\n",
    "    \"\"\"\n",
    "    Compare which features are most important for each group.\n",
    "    Helps identify if model relies on different features for different groups.\n",
    "    \"\"\"\n",
    "    print(\"\\nTop Features by Group (for fairness analysis):\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for group, importance in group_shap_dict.items():\n",
    "        top_features = importance.head(top_k).index.tolist()\n",
    "        print(f\"{group:25} -> {', '.join(top_features)}\")\n",
    "\n",
    "    # Find features that appear in top K for some groups but not others\n",
    "    all_top_features = set()\n",
    "    group_top_features = {}\n",
    "\n",
    "    for group, importance in group_shap_dict.items():\n",
    "        top = set(importance.head(top_k).index)\n",
    "        group_top_features[group] = top\n",
    "        all_top_features.update(top)\n",
    "\n",
    "    print(\n",
    "        f\"\\nTotal unique features in any group's top {top_k}: {len(all_top_features)}\"\n",
    "    )\n",
    "\n",
    "    # Features that don't appear in all groups' top K\n",
    "    divergent_features = []\n",
    "    for feature in all_top_features:\n",
    "        groups_with_feature = [\n",
    "            g for g, tops in group_top_features.items() if feature in tops\n",
    "        ]\n",
    "        if len(groups_with_feature) < len(group_shap_dict):\n",
    "            divergent_features.append((feature, groups_with_feature))\n",
    "\n",
    "    if divergent_features:\n",
    "        print(f\"\\nFeatures with divergent importance across groups:\")\n",
    "        for feature, groups in divergent_features:\n",
    "            print(f\"  - {feature}: important for {groups}\")\n",
    "    else:\n",
    "        print(\"\\nAll top features are consistent across groups\")\n",
    "\n",
    "    return divergent_features\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 24: Compare Feature Importance\n",
    "# ============================================================================\n",
    "\n",
    "# Compare feature importance across groups\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON BY RACE/ETHNICITY\")\n",
    "print(\"=\" * 70)\n",
    "race_divergent = compare_group_feature_importance(race_shap, top_k=5)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON BY SEX\")\n",
    "print(\"=\" * 70)\n",
    "sex_divergent = compare_group_feature_importance(sex_shap, top_k=5)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 25: Local Explanation Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def local_explanation(explainer, model, X_row, top_k=5):\n",
    "    \"\"\"\n",
    "    Generate a local SHAP explanation for a single individual.\n",
    "    Shows which features most increased/decreased their predicted risk.\n",
    "    \"\"\"\n",
    "    x = X_row.values.reshape(1, -1)\n",
    "\n",
    "    # Get SHAP values\n",
    "    shap_vals_raw = explainer.shap_values(x)\n",
    "\n",
    "    # Handle list format\n",
    "    if isinstance(shap_vals_raw, list):\n",
    "        shap_vals = shap_vals_raw[1][0]  # Class 1, first sample\n",
    "        base = explainer.expected_value[1]\n",
    "    else:\n",
    "        shap_vals = shap_vals_raw[0]\n",
    "        base = explainer.expected_value\n",
    "\n",
    "    # Prediction\n",
    "    proba = model.predict_proba(x)[0, 1]\n",
    "\n",
    "    # Get top contributing features\n",
    "    contrib = pd.Series(shap_vals, index=X_row.index)\n",
    "    pos = contrib[contrib > 0].sort_values(ascending=False).head(top_k)\n",
    "    neg = contrib[contrib < 0].sort_values(ascending=True).head(top_k)\n",
    "\n",
    "    return {\n",
    "        \"prediction_proba\": float(proba),\n",
    "        \"base_value\": float(base),\n",
    "        \"top_positive\": list(pos.items()),\n",
    "        \"top_negative\": list(neg.items()),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 26: Generate Local Explanation Example\n",
    "# ============================================================================\n",
    "\n",
    "# Example: Get local explanation for first person in test set\n",
    "idx = X_test.index[0]\n",
    "row = X_test.loc[idx]\n",
    "local_exp = local_explanation(explainer, final_lgb, row)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOCAL EXPLANATION FOR INDIVIDUAL\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Person ID: {ids_test.iloc[0]}\")\n",
    "print(f\"Predicted probability: {local_exp['prediction_proba']:.3f}\")\n",
    "print(f\"Base value (avg): {local_exp['base_value']:.3f}\")\n",
    "print(\"\\nTop features INCREASING risk:\")\n",
    "for feat, val in local_exp[\"top_positive\"]:\n",
    "    print(f\"  {feat:30} +{val:.4f}\")\n",
    "print(\"\\nTop features DECREASING risk:\")\n",
    "for feat, val in local_exp[\"top_negative\"]:\n",
    "    print(f\"  {feat:30} {val:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 27: Summary Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def summarize_fairness_findings(race_metrics, sex_metrics, df_fair):\n",
    "    \"\"\"\n",
    "    Generate a summary of key fairness findings.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FAIRNESS ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Overall model performance\n",
    "    print(\"\\n1. OVERALL MODEL PERFORMANCE:\")\n",
    "    print(f\"   - Test set size: {len(df_fair)}\")\n",
    "    print(\n",
    "        f\"   - Positive cases: {df_fair['y_true'].sum()} ({df_fair['y_true'].mean():.1%})\"\n",
    "    )\n",
    "    print(f\"   - Mean predicted probability: {df_fair['y_pred_proba'].mean():.3f}\")\n",
    "    print(f\"   - Positive prediction rate: {df_fair['y_pred'].mean():.3f}\")\n",
    "\n",
    "    # Race/ethnicity disparities\n",
    "    print(\"\\n2. RACE/ETHNICITY DISPARITIES:\")\n",
    "    recall_range = race_metrics[\"recall\"].max() - race_metrics[\"recall\"].min()\n",
    "    fnr_range = (\n",
    "        race_metrics[\"false_negative_rate\"].max()\n",
    "        - race_metrics[\"false_negative_rate\"].min()\n",
    "    )\n",
    "    print(f\"   - Recall range: {recall_range:.3f} (max-min across groups)\")\n",
    "    print(f\"   - False negative rate range: {fnr_range:.3f}\")\n",
    "    print(\n",
    "        f\"   - Highest recall: {race_metrics.loc[race_metrics['recall'].idxmax(), 'race_ethnicity']} ({race_metrics['recall'].max():.3f})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   - Lowest recall: {race_metrics.loc[race_metrics['recall'].idxmin(), 'race_ethnicity']} ({race_metrics['recall'].min():.3f})\"\n",
    "    )\n",
    "\n",
    "    # Sex disparities\n",
    "    print(\"\\n3. SEX DISPARITIES:\")\n",
    "    male_recall = sex_metrics.loc[sex_metrics[\"sex\"] == \"Male\", \"recall\"].values[0]\n",
    "    female_recall = sex_metrics.loc[sex_metrics[\"sex\"] == \"Female\", \"recall\"].values[0]\n",
    "    recall_diff = male_recall - female_recall\n",
    "    print(f\"   - Male recall: {male_recall:.3f}\")\n",
    "    print(f\"   - Female recall: {female_recall:.3f}\")\n",
    "    print(f\"   - Difference: {recall_diff:.3f}\")\n",
    "\n",
    "    # Model reliability by group size\n",
    "    print(\"\\n4. GROUP SIZES:\")\n",
    "    print(\"   Race/Ethnicity:\")\n",
    "    for _, row in race_metrics.iterrows():\n",
    "        print(f\"     - {row['race_ethnicity']:20} {row['count']:5} samples\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 28: Generate Summary\n",
    "# ============================================================================\n",
    "\n",
    "# Generate summary\n",
    "summarize_fairness_findings(race_metrics, sex_metrics, df_fair)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 29: Save Results\n",
    "# ============================================================================\n",
    "\n",
    "# Create output directory\n",
    "output_dir = pathlib.Path(\"fairness_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save fairness metrics\n",
    "race_metrics.to_parquet(output_dir / \"race_metrics.parquet\", index=False)\n",
    "sex_metrics.to_parquet(output_dir / \"sex_metrics.parquet\", index=False)\n",
    "poverty_metrics.to_parquet(output_dir / \"poverty_metrics.parquet\", index=False)\n",
    "insurance_metrics.to_parquet(output_dir / \"insurance_metrics.parquet\", index=False)\n",
    "\n",
    "# Save disparities\n",
    "race_disparities.to_parquet(output_dir / \"race_disparities.parquet\", index=False)\n",
    "sex_disparities.to_parquet(output_dir / \"sex_disparities.parquet\", index=False)\n",
    "poverty_disparities.to_parquet(output_dir / \"poverty_disparities.parquet\", index=False)\n",
    "insurance_disparities.to_parquet(\n",
    "    output_dir / \"insurance_disparities.parquet\", index=False\n",
    ")\n",
    "\n",
    "# Save global SHAP importance\n",
    "global_importance.to_parquet(output_dir / \"global_shap_importance.parquet\", index=False)\n",
    "\n",
    "# Save fairness dataframe with SHAP values (for interactive playground)\n",
    "df_fair_shap.to_parquet(output_dir / \"df_fair_with_shap.parquet\", index=False)\n",
    "\n",
    "# Save explainer for real-time explanations\n",
    "joblib.dump(explainer, output_dir / \"shap_explainer.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTS SAVED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Files saved: {len(list(output_dir.glob('*')))}\")\n",
    "print(\"\\nSaved files:\")\n",
    "for f in sorted(output_dir.glob(\"*\")):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 30: Age Group Analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Create age groups for additional analysis\n",
    "df_fair_shap[\"age_group\"] = pd.cut(\n",
    "    df_fair_shap[\"age\"],\n",
    "    bins=[0, 18, 35, 50, 65, 100],\n",
    "    labels=[\"0-18\", \"19-35\", \"36-50\", \"51-65\", \"65+\"],\n",
    ")\n",
    "\n",
    "# Compute metrics by age group\n",
    "age_metrics = compute_group_metrics(df_fair_shap, \"age_group\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FAIRNESS METRICS BY AGE GROUP\")\n",
    "print(\"=\" * 70)\n",
    "print(age_metrics.to_string(index=False))\n",
    "\n",
    "# Save age metrics\n",
    "age_metrics.to_parquet(output_dir / \"age_metrics.parquet\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 31: Final Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nThis notebook has:\")\n",
    "print(\"1. ✓ Loaded model artifacts and test data\")\n",
    "print(\"2. ✓ Merged predictions with demographics\")\n",
    "print(\"3. ✓ Computed fairness metrics across multiple demographic groups\")\n",
    "print(\"4. ✓ Calculated disparity gaps versus reference groups\")\n",
    "print(\"5. ✓ Generated global SHAP feature importance\")\n",
    "print(\"6. ✓ Computed group-specific SHAP importance\")\n",
    "print(\"7. ✓ Identified divergent features across groups\")\n",
    "print(\"8. ✓ Created local explanation framework\")\n",
    "print(\"9. ✓ Saved all results for the fairness playground\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"- Build interactive playground using saved results\")\n",
    "print(\"- Implement counterfactual explanations\")\n",
    "print(\"- Create visualizations for fairness metrics\")\n",
    "print(\"- Add threshold optimization analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
