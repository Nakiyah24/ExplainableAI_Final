{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69816cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import joblib\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "\n",
    "# Display options (optional)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e723247",
   "metadata": {},
   "source": [
    "About the Data:\n",
    "- https://meps.ahrq.gov/mepsweb/data_stats/download_data_files.jsp\n",
    "- https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_results.jsp?cboDataYear=All&cboDataTypeY=1%2CHousehold+Full+Year+File&buttonYearandDataType=Search&cboPufNumber=All&SearchTitle=Consolidated+Data\n",
    "\n",
    "\n",
    "For this project, I’m working with a cleaned subset of the MEPS (Medical Expenditure Panel Survey) dataset. Specifically 2023 Full Year Consolidated Data File (PUF Number: HC251). \n",
    "\n",
    "MEPS is a national healthcare survey that tracks people’s demographics, insurance status, health behaviors, and medical usage and is also commonly used in fairness and healthcare modeling scenarios due to it's granularity.\n",
    "\n",
    "In my case, I’m using MEPS because it gives me:\n",
    "\n",
    "1. the key demographic variables I need for fairness analysis (age, sex, race/ethnicity, income, poverty level, insurance, etc.),\n",
    "\n",
    "2. the health-status variables my model actually uses to make predictions, and enough variation across groups to see where bias shows up.\n",
    "\n",
    "My end goal in this notebook to export all of this into a parquetdf_meta, which will become the backbone for both parts of my app:\n",
    "\n",
    "1. Fairness Playground – where users change demographics and see how the prediction shifts.\n",
    "\n",
    "2. Name Bias Lab – where the health profile stays constant but the first name changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548cdd0",
   "metadata": {},
   "source": [
    "The first goal of this project is to train a predictive model that will power the Fairness Playground.\n",
    "\n",
    "Based on the literature I reviewed — including recent work showing strong performance of boosting methods on structured healthcare data — gradient-boosting models tend to outperform more traditional approaches for this kind of problem. They capture non-linear relationships, handle mixed data types, and generally require very little feature engineering.\n",
    "(Example reference: ScienceDirect, “Tabular Data Healthcare Prediction Using Gradient Boosting Methods,” 2025)\n",
    "- https://www.sciencedirect.com/science/article/pii/S2588914125000140\n",
    "\n",
    "Because of that, I’m using two state-of-the-art boosting models:\n",
    "\n",
    "1. LightGBM\n",
    "2. XGBoost\n",
    "\n",
    "Both are fast, stable, and well-suited for tabular datasets like MEPS. They also work seamlessly with SHAP, which matters because the Fairness Playground relies on real-time model explanations whenever users change input values.\n",
    "\n",
    "These models will form the backbone of the prediction engine used throughout the fairness module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97aebb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "data_path = \"./data/meps_2023/\"\n",
    "main_df = \"h251.xlsx\"\n",
    "\n",
    "# reading as polars for speed\n",
    "df_pl_raw = pl.read_excel(f\"{data_path}{main_df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a8d90",
   "metadata": {},
   "source": [
    "MEPS has hundreds of fields, but for the fairness playground I only keep the variables that matter most for understanding differences in healthcare predictions. These include core demographics (age, sex, race, ethnicity), socioeconomic indicators (income, education, poverty level), and basic access-to-care variables like insurance coverage. According to the MEPS documentation, these are the primary factors that shape both healthcare utilization and disparities across groups, so they’re essential for fairness analysis.\n",
    "\n",
    "I also keep a small set of high-level health status and utilization variables — things like self-rated health, chronic condition flags, and counts of visits or expenditures. These are standard MEPS indicators used in most prediction studies, and they give the model enough signal to make meaningful predictions without going into overly detailed or sensitive medical fields. Keeping this narrowed, intentional subset helps the model stay interpretable and allows the fairness playground to compare predictions across groups in a controlled, transparent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aefce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping MEPS raw variable names to cleaner names, grouped logically\n",
    "\n",
    "rename_map = {\n",
    "    # Demographics\n",
    "    \"DUPERSID\": \"person_id\",\n",
    "    \"AGELAST\": \"age\",\n",
    "    \"SEX\": \"sex\",\n",
    "    \"RACEV1X\": \"race_simple\",\n",
    "    \"RACETHX\": \"race_ethnicity\",\n",
    "    \"HISPANX\": \"hispanic\",\n",
    "    \"BORNUSA\": \"born_in_usa\",\n",
    "    \"YRSINUS\": \"years_in_us\",\n",
    "    # Socioeconomic indicators\n",
    "    \"EDUCYR\": \"education_years\",\n",
    "    \"FAMINC23\": \"family_income\",\n",
    "    \"POVCAT23\": \"poverty_category\",\n",
    "    \"REGION23\": \"region\",\n",
    "    # Insurance and access to care\n",
    "    \"INSCOV23\": \"insurance_coverage\",\n",
    "    \"INSURC23\": \"insurance_category\",\n",
    "    # Self-reported health\n",
    "    \"RTHLTH53\": \"self_rated_health\",\n",
    "    \"MNHLTH53\": \"self_rated_mental_health\",\n",
    "    \"ADSMOK42\": \"smoker\",\n",
    "    # Chronic conditions\n",
    "    \"HIBPDX\": \"hypertension_dx\",\n",
    "    \"CHDDX\": \"coronary_hd_dx\",\n",
    "    \"ASTHDX\": \"asthma_dx\",\n",
    "    \"DIABDX_M18\": \"diabetes_dx\",\n",
    "    # Healthcare utilization\n",
    "    \"OBTOTV23\": \"office_visits\",\n",
    "    \"OPTOTV23\": \"outpatient_visits\",\n",
    "    \"ERTOT23\": \"er_visits\",\n",
    "    \"DVTOT23\": \"total_visits\",\n",
    "    \"TOTEXP23\": \"total_expenditures\",\n",
    "    \"IPDIS23\": \"inpatient_discharges\",\n",
    "    \"IPTEXP23\": \"inpatient_expenditures\",\n",
    "    \"IPNGTD23\": \"inpatient_nights\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b36e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the rename_map keys as keep_cols so nothing gets truncated\n",
    "cols_to_keep = list(rename_map.keys())\n",
    "df_pl = df_pl_raw.select(cols_to_keep).rename(rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71948edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18919, 29)\n"
     ]
    }
   ],
   "source": [
    "# converting to pandas df\n",
    "df_pd = df_pl.to_pandas()\n",
    "\n",
    "print(df_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb069429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "person_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race_simple",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race_ethnicity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hispanic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "born_in_usa",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "years_in_us",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education_years",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family_income",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "poverty_category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "insurance_coverage",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "insurance_category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "self_rated_health",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "self_rated_mental_health",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "smoker",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hypertension_dx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "coronary_hd_dx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asthma_dx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "diabetes_dx",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "office_visits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outpatient_visits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "er_visits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_visits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_expenditures",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inpatient_discharges",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inpatient_expenditures",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inpatient_nights",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "da485248-d0ea-482c-a5eb-3b42d9feeb47",
       "rows": [
        [
         "0",
         "2790002101",
         "58",
         "2",
         "2",
         "3",
         "2",
         "1",
         "-1",
         "17",
         "130700",
         "5",
         "2",
         "1",
         "1",
         "4",
         "3",
         "2",
         "2",
         "2",
         "2",
         "1",
         "3",
         "1",
         "0",
         "0",
         "646",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "2790002102",
         "27",
         "1",
         "2",
         "3",
         "2",
         "1",
         "-1",
         "12",
         "130700",
         "5",
         "2",
         "1",
         "1",
         "2",
         "2",
         "-1",
         "2",
         "2",
         "1",
         "2",
         "1",
         "0",
         "0",
         "2",
         "1894",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "2790004101",
         "49",
         "2",
         "1",
         "2",
         "2",
         "1",
         "-1",
         "17",
         "87000",
         "5",
         "2",
         "1",
         "1",
         "1",
         "1",
         "2",
         "2",
         "2",
         "2",
         "2",
         "1",
         "0",
         "0",
         "1",
         "986",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "2790006101",
         "75",
         "2",
         "1",
         "2",
         "2",
         "1",
         "-1",
         "12",
         "38000",
         "4",
         "2",
         "2",
         "4",
         "2",
         "2",
         "1",
         "1",
         "2",
         "2",
         "1",
         "3",
         "0",
         "0",
         "0",
         "1312",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "2790006102",
         "23",
         "1",
         "1",
         "2",
         "2",
         "1",
         "-1",
         "11",
         "38000",
         "4",
         "2",
         "2",
         "2",
         "2",
         "2",
         "-1",
         "2",
         "2",
         "2",
         "2",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_simple</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>years_in_us</th>\n",
       "      <th>education_years</th>\n",
       "      <th>family_income</th>\n",
       "      <th>poverty_category</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_coverage</th>\n",
       "      <th>insurance_category</th>\n",
       "      <th>self_rated_health</th>\n",
       "      <th>self_rated_mental_health</th>\n",
       "      <th>smoker</th>\n",
       "      <th>hypertension_dx</th>\n",
       "      <th>coronary_hd_dx</th>\n",
       "      <th>asthma_dx</th>\n",
       "      <th>diabetes_dx</th>\n",
       "      <th>office_visits</th>\n",
       "      <th>outpatient_visits</th>\n",
       "      <th>er_visits</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>total_expenditures</th>\n",
       "      <th>inpatient_discharges</th>\n",
       "      <th>inpatient_expenditures</th>\n",
       "      <th>inpatient_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2790002101</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>130700</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2790002102</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>130700</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2790004101</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>87000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790006101</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>38000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2790006102</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>38000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_id  age  sex  race_simple  race_ethnicity  hispanic  born_in_usa  \\\n",
       "0  2790002101   58    2            2               3         2            1   \n",
       "1  2790002102   27    1            2               3         2            1   \n",
       "2  2790004101   49    2            1               2         2            1   \n",
       "3  2790006101   75    2            1               2         2            1   \n",
       "4  2790006102   23    1            1               2         2            1   \n",
       "\n",
       "   years_in_us  education_years  family_income  poverty_category  region  \\\n",
       "0           -1               17         130700                 5       2   \n",
       "1           -1               12         130700                 5       2   \n",
       "2           -1               17          87000                 5       2   \n",
       "3           -1               12          38000                 4       2   \n",
       "4           -1               11          38000                 4       2   \n",
       "\n",
       "   insurance_coverage  insurance_category  self_rated_health  \\\n",
       "0                   1                   1                  4   \n",
       "1                   1                   1                  2   \n",
       "2                   1                   1                  1   \n",
       "3                   2                   4                  2   \n",
       "4                   2                   2                  2   \n",
       "\n",
       "   self_rated_mental_health  smoker  hypertension_dx  coronary_hd_dx  \\\n",
       "0                         3       2                2               2   \n",
       "1                         2      -1                2               2   \n",
       "2                         1       2                2               2   \n",
       "3                         2       1                1               2   \n",
       "4                         2      -1                2               2   \n",
       "\n",
       "   asthma_dx  diabetes_dx  office_visits  outpatient_visits  er_visits  \\\n",
       "0          2            1              3                  1          0   \n",
       "1          1            2              1                  0          0   \n",
       "2          2            2              1                  0          0   \n",
       "3          2            1              3                  0          0   \n",
       "4          2            2              0                  0          0   \n",
       "\n",
       "   total_visits  total_expenditures  inpatient_discharges  \\\n",
       "0             0                 646                     0   \n",
       "1             2                1894                     0   \n",
       "2             1                 986                     0   \n",
       "3             0                1312                     0   \n",
       "4             0                   0                     0   \n",
       "\n",
       "   inpatient_expenditures  inpatient_nights  \n",
       "0                       0                 0  \n",
       "1                       0                 0  \n",
       "2                       0                 0  \n",
       "3                       0                 0  \n",
       "4                       0                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9887dd0",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716a4b4",
   "metadata": {},
   "source": [
    "##### Handling special codes\n",
    "MEPS uses special negative values such as –1 (“inapplicable”), –7 (“refused”), –8 (“don’t know”), and –9 (“not ascertained”) to indicate different types of missing data. These aren’t real values, and keeping them would distort both the summary statistics and the model training. For example, the model could mistakenly treat “–8 outpatient visits” or “–9 total expenditures” as meaningful numbers, even though they don’t represent actual behavior. To avoid that, I am going to replace these with 'NAN' before any analysis so they don't show up as fake values or categories.\n",
    "\n",
    "\n",
    "#### Defining target variable\n",
    "For the prediction target, I define a binary variable **`hospitalized`** based on inpatient expenditures: if a person has any positive inpatient spending, I treat that as evidence of at least one hospitalization in the year. To avoid data leakage, I drop the raw inpatient expenditure field from the features after using it to construct the label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c17b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling MEPS special codes for numeric columns\n",
    "#    (-1, -7, -8, -9, -15 --> NaN)\n",
    "\n",
    "SPECIAL_CODES = [-1, -7, -8, -9, -15]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"age\",\n",
    "    \"education_years\",\n",
    "    \"family_income\",\n",
    "    \"years_in_us\",\n",
    "    \"office_visits\",\n",
    "    \"outpatient_visits\",\n",
    "    \"er_visits\",\n",
    "    \"total_visits\",\n",
    "    \"total_expenditures\",\n",
    "    \"inpatient_discharges\",\n",
    "    \"inpatient_expenditures\",\n",
    "    \"inpatient_nights\",\n",
    "]\n",
    "\n",
    "df_pd[numeric_cols] = df_pd[numeric_cols].replace(SPECIAL_CODES, pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d58e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          count          mean           std    min      25%  \\\n",
      "age                     18919.0     43.716581     23.939550    0.0     23.0   \n",
      "family_income           18919.0  98815.895555  91575.419638 -230.0  35000.0   \n",
      "office_visits           18919.0      7.140758     13.784344    0.0      0.0   \n",
      "outpatient_visits       18919.0      1.095195      4.489569    0.0      0.0   \n",
      "er_visits               18919.0      0.224166      0.672914    0.0      0.0   \n",
      "total_visits            18919.0      1.035943      1.688402    0.0      0.0   \n",
      "total_expenditures      18919.0   8422.054125  21664.250470    0.0    299.5   \n",
      "inpatient_discharges    18919.0      0.096728      0.394552    0.0      0.0   \n",
      "inpatient_expenditures  18919.0   1830.599397  11540.246170    0.0      0.0   \n",
      "inpatient_nights        18919.0      0.535599      4.267027    0.0      0.0   \n",
      "\n",
      "                            50%       75%       max  \n",
      "age                        45.0      64.0      85.0  \n",
      "family_income           72800.0  137484.0  747346.0  \n",
      "office_visits               2.0       8.0     419.0  \n",
      "outpatient_visits           0.0       1.0     178.0  \n",
      "er_visits                   0.0       0.0      22.0  \n",
      "total_visits                0.0       2.0      25.0  \n",
      "total_expenditures       1816.0    7087.0  574675.0  \n",
      "inpatient_discharges        0.0       0.0      10.0  \n",
      "inpatient_expenditures      0.0       0.0  458360.0  \n",
      "inpatient_nights            0.0       0.0     264.0  \n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "print(df_pd[numeric_cols].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ddabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling special codes for categorical columns as well\n",
    "SPECIAL_CODES = [-1, -7, -8, -9, -15]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"sex\",\n",
    "    \"race_simple\",\n",
    "    \"race_ethnicity\",\n",
    "    \"hispanic\",\n",
    "    \"poverty_category\",\n",
    "    \"insurance_coverage\",\n",
    "    \"insurance_category\",\n",
    "    \"region\",\n",
    "    \"born_in_usa\",\n",
    "    \"self_rated_health\",\n",
    "    \"self_rated_mental_health\",\n",
    "    \"smoker\",\n",
    "    \"hypertension_dx\",\n",
    "    \"coronary_hd_dx\",\n",
    "    \"asthma_dx\",\n",
    "    \"diabetes_dx\",\n",
    "]\n",
    "\n",
    "# Replacing MEPS special codes with NA in categorical columns\n",
    "df_pd[categorical_cols] = df_pd[categorical_cols].replace(SPECIAL_CODES, pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ca36e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      count      mean       std  min  25%  50%  75%  max\n",
      "sex                 18919.0  1.523601  0.499456  1.0  1.0  2.0  2.0  2.0\n",
      "race_simple         18919.0  1.547386  1.194245  1.0  1.0  1.0  2.0  6.0\n",
      "race_ethnicity      18919.0  2.148052  0.959049  1.0  2.0  2.0  2.0  5.0\n",
      "hispanic            18919.0  1.778635  0.415176  1.0  2.0  2.0  2.0  2.0\n",
      "poverty_category    18919.0  3.708970  1.411587  1.0  3.0  4.0  5.0  5.0\n",
      "insurance_coverage  18919.0  1.485068  0.622105  1.0  1.0  1.0  2.0  3.0\n",
      "insurance_category  18919.0  2.276389  1.609777  1.0  1.0  2.0  3.0  8.0\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check\n",
    "print(df_pd[categorical_cols].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3921d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns converted and imputed\n",
      "years_in_us missing: 0\n",
      "education_years missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Converting columns to numeric\n",
    "df_pd[\"years_in_us\"] = pd.to_numeric(df_pd[\"years_in_us\"], errors=\"coerce\")\n",
    "df_pd[\"education_years\"] = pd.to_numeric(df_pd[\"education_years\"], errors=\"coerce\")\n",
    "\n",
    "# Imputing columns with median\n",
    "df_pd[\"years_in_us\"] = df_pd[\"years_in_us\"].fillna(df_pd[\"years_in_us\"].median())\n",
    "df_pd[\"education_years\"] = df_pd[\"education_years\"].fillna(\n",
    "    df_pd[\"education_years\"].median()\n",
    ")\n",
    "\n",
    "print(\"Numeric columns converted and imputed\")\n",
    "print(f\"years_in_us missing: {df_pd['years_in_us'].isna().sum()}\")\n",
    "print(f\"education_years missing: {df_pd['education_years'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52486493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after one-hot encoding: (18919, 69)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns\n",
    "df_ohe = pd.get_dummies(df_pd, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "print(f\"Shape after one-hot encoding: {df_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a481e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing inpatient_expenditures: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing target values\n",
    "missing_target = df_ohe[\"inpatient_expenditures\"].isna().sum()\n",
    "print(f\"Missing inpatient_expenditures: {missing_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbdeffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on a copy that has valid inpatient_expenditures\n",
    "df_model = df_ohe[df_ohe[\"inpatient_expenditures\"].notna()].copy()\n",
    "\n",
    "# Define target: hospitalized = 1 if inpatient_expenditures > 0\n",
    "df_model[\"hospitalized\"] = (df_model[\"inpatient_expenditures\"] > 0).astype(int)\n",
    "\n",
    "# Drop leakage features from X\n",
    "leakage_cols = [\"inpatient_expenditures\", \"inpatient_nights\", \"inpatient_discharges\"]\n",
    "df_model = df_model.drop(columns=leakage_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29e205ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsed Chatgpt-5 on 21 Nov to clean and encode the feature columns\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Used Chatgpt-5 on 21 Nov to clean and encode the feature columns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345ea2e",
   "metadata": {},
   "source": [
    "### Quick Sanity Checks and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd31863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    person_id  age  years_in_us  education_years  family_income  \\\n",
      "0  2790002101   58          5.0             17.0         130700   \n",
      "1  2790002102   27          5.0             12.0         130700   \n",
      "2  2790004101   49          5.0             17.0          87000   \n",
      "3  2790006101   75          5.0             12.0          38000   \n",
      "4  2790006102   23          5.0             11.0          38000   \n",
      "\n",
      "   office_visits  outpatient_visits  er_visits  total_visits  \\\n",
      "0              3                  1          0             0   \n",
      "1              1                  0          0             2   \n",
      "2              1                  0          0             1   \n",
      "3              3                  0          0             0   \n",
      "4              0                  0          0             0   \n",
      "\n",
      "   total_expenditures  sex_1  sex_2  race_simple_1  race_simple_2  \\\n",
      "0                 646  False   True          False           True   \n",
      "1                1894   True  False          False           True   \n",
      "2                 986  False   True           True          False   \n",
      "3                1312  False   True           True          False   \n",
      "4                   0   True  False           True          False   \n",
      "\n",
      "   race_simple_3  race_simple_4  race_simple_6  race_ethnicity_1  \\\n",
      "0          False          False          False             False   \n",
      "1          False          False          False             False   \n",
      "2          False          False          False             False   \n",
      "3          False          False          False             False   \n",
      "4          False          False          False             False   \n",
      "\n",
      "   race_ethnicity_2  race_ethnicity_3  race_ethnicity_4  race_ethnicity_5  \\\n",
      "0             False              True             False             False   \n",
      "1             False              True             False             False   \n",
      "2              True             False             False             False   \n",
      "3              True             False             False             False   \n",
      "4              True             False             False             False   \n",
      "\n",
      "   hispanic_1  hispanic_2  poverty_category_1  poverty_category_2  \\\n",
      "0       False        True               False               False   \n",
      "1       False        True               False               False   \n",
      "2       False        True               False               False   \n",
      "3       False        True               False               False   \n",
      "4       False        True               False               False   \n",
      "\n",
      "   poverty_category_3  poverty_category_4  poverty_category_5  \\\n",
      "0               False               False                True   \n",
      "1               False               False                True   \n",
      "2               False               False                True   \n",
      "3               False                True               False   \n",
      "4               False                True               False   \n",
      "\n",
      "   insurance_coverage_1  insurance_coverage_2  insurance_coverage_3  \\\n",
      "0                  True                 False                 False   \n",
      "1                  True                 False                 False   \n",
      "2                  True                 False                 False   \n",
      "3                 False                  True                 False   \n",
      "4                 False                  True                 False   \n",
      "\n",
      "   insurance_category_1  insurance_category_2  insurance_category_3  \\\n",
      "0                  True                 False                 False   \n",
      "1                  True                 False                 False   \n",
      "2                  True                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                  True                 False   \n",
      "\n",
      "   insurance_category_4  insurance_category_5  insurance_category_6  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                  True                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   insurance_category_7  insurance_category_8  region_1  region_2  region_3  \\\n",
      "0                 False                 False     False      True     False   \n",
      "1                 False                 False     False      True     False   \n",
      "2                 False                 False     False      True     False   \n",
      "3                 False                 False     False      True     False   \n",
      "4                 False                 False     False      True     False   \n",
      "\n",
      "   region_4  born_in_usa_1  born_in_usa_2  self_rated_health_1  \\\n",
      "0     False           True          False                False   \n",
      "1     False           True          False                False   \n",
      "2     False           True          False                 True   \n",
      "3     False           True          False                False   \n",
      "4     False           True          False                False   \n",
      "\n",
      "   self_rated_health_2  self_rated_health_3  self_rated_health_4  \\\n",
      "0                False                False                 True   \n",
      "1                 True                False                False   \n",
      "2                False                False                False   \n",
      "3                 True                False                False   \n",
      "4                 True                False                False   \n",
      "\n",
      "   self_rated_health_5  self_rated_mental_health_1  \\\n",
      "0                False                       False   \n",
      "1                False                       False   \n",
      "2                False                        True   \n",
      "3                False                       False   \n",
      "4                False                       False   \n",
      "\n",
      "   self_rated_mental_health_2  self_rated_mental_health_3  \\\n",
      "0                       False                        True   \n",
      "1                        True                       False   \n",
      "2                       False                       False   \n",
      "3                        True                       False   \n",
      "4                        True                       False   \n",
      "\n",
      "   self_rated_mental_health_4  self_rated_mental_health_5  smoker_1  smoker_2  \\\n",
      "0                       False                       False     False      True   \n",
      "1                       False                       False     False     False   \n",
      "2                       False                       False     False      True   \n",
      "3                       False                       False      True     False   \n",
      "4                       False                       False     False     False   \n",
      "\n",
      "   hypertension_dx_1  hypertension_dx_2  coronary_hd_dx_1  coronary_hd_dx_2  \\\n",
      "0              False               True             False              True   \n",
      "1              False               True             False              True   \n",
      "2              False               True             False              True   \n",
      "3               True              False             False              True   \n",
      "4              False               True             False              True   \n",
      "\n",
      "   asthma_dx_1  asthma_dx_2  diabetes_dx_1  diabetes_dx_2  hospitalized  \n",
      "0        False         True           True          False             0  \n",
      "1         True        False          False           True             0  \n",
      "2        False         True          False           True             0  \n",
      "3        False         True           True          False             0  \n",
      "4        False         True          False           True             0  \n"
     ]
    }
   ],
   "source": [
    "print(df_model.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818b1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:\n",
      "hospitalized\n",
      "0    0.926265\n",
      "1    0.073735\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for class imbalance\n",
    "print(\"Class balance:\")\n",
    "print(df_model[\"hospitalized\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2b26e",
   "metadata": {},
   "source": [
    "Only 7.37% of individuals in the MEPS dataset experienced any inpatient hospitalization while 93.7% did not, which means the dataset is extremely imbalanced. Nonetheless this makes because hospitalization is relatively rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6fa8022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18919 entries, 0 to 18918\n",
      "Data columns (total 67 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   person_id                   18919 non-null  object \n",
      " 1   age                         18919 non-null  int64  \n",
      " 2   years_in_us                 18919 non-null  float64\n",
      " 3   education_years             18919 non-null  float64\n",
      " 4   family_income               18919 non-null  int64  \n",
      " 5   office_visits               18919 non-null  int64  \n",
      " 6   outpatient_visits           18919 non-null  int64  \n",
      " 7   er_visits                   18919 non-null  int64  \n",
      " 8   total_visits                18919 non-null  int64  \n",
      " 9   total_expenditures          18919 non-null  int64  \n",
      " 10  sex_1                       18919 non-null  bool   \n",
      " 11  sex_2                       18919 non-null  bool   \n",
      " 12  race_simple_1               18919 non-null  bool   \n",
      " 13  race_simple_2               18919 non-null  bool   \n",
      " 14  race_simple_3               18919 non-null  bool   \n",
      " 15  race_simple_4               18919 non-null  bool   \n",
      " 16  race_simple_6               18919 non-null  bool   \n",
      " 17  race_ethnicity_1            18919 non-null  bool   \n",
      " 18  race_ethnicity_2            18919 non-null  bool   \n",
      " 19  race_ethnicity_3            18919 non-null  bool   \n",
      " 20  race_ethnicity_4            18919 non-null  bool   \n",
      " 21  race_ethnicity_5            18919 non-null  bool   \n",
      " 22  hispanic_1                  18919 non-null  bool   \n",
      " 23  hispanic_2                  18919 non-null  bool   \n",
      " 24  poverty_category_1          18919 non-null  bool   \n",
      " 25  poverty_category_2          18919 non-null  bool   \n",
      " 26  poverty_category_3          18919 non-null  bool   \n",
      " 27  poverty_category_4          18919 non-null  bool   \n",
      " 28  poverty_category_5          18919 non-null  bool   \n",
      " 29  insurance_coverage_1        18919 non-null  bool   \n",
      " 30  insurance_coverage_2        18919 non-null  bool   \n",
      " 31  insurance_coverage_3        18919 non-null  bool   \n",
      " 32  insurance_category_1        18919 non-null  bool   \n",
      " 33  insurance_category_2        18919 non-null  bool   \n",
      " 34  insurance_category_3        18919 non-null  bool   \n",
      " 35  insurance_category_4        18919 non-null  bool   \n",
      " 36  insurance_category_5        18919 non-null  bool   \n",
      " 37  insurance_category_6        18919 non-null  bool   \n",
      " 38  insurance_category_7        18919 non-null  bool   \n",
      " 39  insurance_category_8        18919 non-null  bool   \n",
      " 40  region_1                    18919 non-null  bool   \n",
      " 41  region_2                    18919 non-null  bool   \n",
      " 42  region_3                    18919 non-null  bool   \n",
      " 43  region_4                    18919 non-null  bool   \n",
      " 44  born_in_usa_1               18919 non-null  bool   \n",
      " 45  born_in_usa_2               18919 non-null  bool   \n",
      " 46  self_rated_health_1         18919 non-null  bool   \n",
      " 47  self_rated_health_2         18919 non-null  bool   \n",
      " 48  self_rated_health_3         18919 non-null  bool   \n",
      " 49  self_rated_health_4         18919 non-null  bool   \n",
      " 50  self_rated_health_5         18919 non-null  bool   \n",
      " 51  self_rated_mental_health_1  18919 non-null  bool   \n",
      " 52  self_rated_mental_health_2  18919 non-null  bool   \n",
      " 53  self_rated_mental_health_3  18919 non-null  bool   \n",
      " 54  self_rated_mental_health_4  18919 non-null  bool   \n",
      " 55  self_rated_mental_health_5  18919 non-null  bool   \n",
      " 56  smoker_1                    18919 non-null  bool   \n",
      " 57  smoker_2                    18919 non-null  bool   \n",
      " 58  hypertension_dx_1           18919 non-null  bool   \n",
      " 59  hypertension_dx_2           18919 non-null  bool   \n",
      " 60  coronary_hd_dx_1            18919 non-null  bool   \n",
      " 61  coronary_hd_dx_2            18919 non-null  bool   \n",
      " 62  asthma_dx_1                 18919 non-null  bool   \n",
      " 63  asthma_dx_2                 18919 non-null  bool   \n",
      " 64  diabetes_dx_1               18919 non-null  bool   \n",
      " 65  diabetes_dx_2               18919 non-null  bool   \n",
      " 66  hospitalized                18919 non-null  int64  \n",
      "dtypes: bool(56), float64(2), int64(8), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "print(df_model.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b9245",
   "metadata": {},
   "source": [
    "Overall, this processed dataset currently contains 18,919 rows and 94 columns. Most of the features are one-hot encoded categorical variables stored as booleans (great for boosting methods), along with a set of numeric fields capturing age, income, visits, and expenditures. Both, `years_in_us` and `education_years` still come in as object types because MEPS encodes missing data using negative codes. I’ll convert both to numeric and impute their missing values using the median so the model receives clean, consistent inputs.\n",
    "\n",
    "Aside from those two fields, the dataset has no remaining missing values, and all categorical variables have already been fully expanded into dummy variables. The wide structure means the model can learn group-specific patterns while still being stable for gradient boosting. Overall, once those two numeric fields are fixed and imputed, the dataset is fully ready for supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a01b8e",
   "metadata": {},
   "source": [
    "### Splitting datasets\n",
    "\n",
    "To evaluate the model properly, I will split the dataset into training and testing sets using a stratified split. Since hospitalization is relatively rare in this MEPS sample (with around 7% of cases), stratification would ensure that both subsets maintain the same class balance. This prevents the model from being trained or evaluated on an artificially skewed distribution and will give a more realistic sense of performance.\n",
    "\n",
    "In addition, because of the imbalance, I will use StratifiedKFold for cross-validation wherein each fold will contain roughly the same proportion of hospitalized vs. non-hospitalized cases as the full dataset. That consistency avoids folds where the minority class is underrepresented or missing entirely, which can lead to unstable or overly optimistic estimates. Using stratified folds makes the evaluation much more reliable and gives a clearer picture of how well the model will generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac266c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split shapes:\n",
      "  X_train: (15135, 66)\n",
      "  X_test: (3784, 66)\n",
      "  y_train balance: {0: 0.9262636273538156, 1: 0.07373637264618434}\n",
      "  y_test balance: {0: 0.9262684989429175, 1: 0.07373150105708245}\n",
      "\n",
      "✓ After dropping person_id:\n",
      "  X_train: (15135, 65)\n",
      "  X_test: (3784, 65)\n"
     ]
    }
   ],
   "source": [
    "# Keep person_id separately so we can split it alongside X and y\n",
    "ids = df_model[\"person_id\"]\n",
    "\n",
    "# Features and target\n",
    "X = df_model.drop(columns=[\"hospitalized\"])\n",
    "y = df_model[\"hospitalized\"]\n",
    "\n",
    "# Stratified train/test split to respect imbalance\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Split shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_train balance: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  y_test balance: {y_test.value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "# Now we drop Person_ids from X_train, X_test\n",
    "X_train = X_train.drop(columns=[\"person_id\"])\n",
    "X_test = X_test.drop(columns=[\"person_id\"])\n",
    "\n",
    "print(f\"\\n✓ After dropping person_id:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa4bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified 5-fold cross-validation to preserve class balance in each fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f6c0a",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ad820",
   "metadata": {},
   "source": [
    "#### 1. Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4caaaa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 893, number of negative: 11215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 897\n",
      "[LightGBM] [Info] Number of data points in the train set: 12108, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold 1 ROC-AUC: 0.958\n",
      "[LightGBM] [Info] Number of positive: 893, number of negative: 11215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 894\n",
      "[LightGBM] [Info] Number of data points in the train set: 12108, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold 2 ROC-AUC: 0.960\n",
      "[LightGBM] [Info] Number of positive: 893, number of negative: 11215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 12108, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold 3 ROC-AUC: 0.955\n",
      "[LightGBM] [Info] Number of positive: 893, number of negative: 11215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 898\n",
      "[LightGBM] [Info] Number of data points in the train set: 12108, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold 4 ROC-AUC: 0.954\n",
      "[LightGBM] [Info] Number of positive: 892, number of negative: 11216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 12108, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold 5 ROC-AUC: 0.957\n",
      "\n",
      "Mean ROC-AUC: 0.957 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "# LightGBM model (tuned lightly for tabular + imbalance)\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "lgb_cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), start=1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    lgb_model.fit(X_tr, y_tr)\n",
    "    val_pred = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    lgb_cv_scores.append(auc)\n",
    "    print(f\"Fold {fold} ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nMean ROC-AUC: {np.mean(lgb_cv_scores):.3f} ± {np.std(lgb_cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a43041",
   "metadata": {},
   "source": [
    "#### 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd765d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ROC-AUC: 0.955\n",
      "Fold 2 ROC-AUC: 0.958\n",
      "Fold 3 ROC-AUC: 0.957\n",
      "Fold 4 ROC-AUC: 0.956\n",
      "Fold 5 ROC-AUC: 0.957\n",
      "\n",
      "Mean ROC-AUC: 0.956 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance for XGBoost\n",
    "pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=pos_weight,  # imbalance handling\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xgb_cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), start=1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    xgb_model.fit(X_tr, y_tr)\n",
    "    val_pred = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    xgb_cv_scores.append(auc)\n",
    "    print(f\"Fold {fold} ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nMean ROC-AUC: {np.mean(xgb_cv_scores):.3f} ± {np.std(xgb_cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59848c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPARISON\n",
      "LightGBM Mean ROC-AUC: 0.957 ± 0.002\n",
      "XGBoost Mean ROC-AUC:  0.956 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL COMPARISON\")\n",
    "print(\n",
    "    f\"LightGBM Mean ROC-AUC: {np.mean(lgb_cv_scores):.3f} ± {np.std(lgb_cv_scores):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"XGBoost Mean ROC-AUC:  {np.mean(xgb_cv_scores):.3f} ± {np.std(xgb_cv_scores):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bffee",
   "metadata": {},
   "source": [
    "After running stratified 5-fold cross-validation on both LightGBM and XGBoost, the two models performed almost identically. Each model had a mean ROC-AUC of roughly 0.956-0.957 with very small standard deviations across folds. This means both gradient-boosting methods are strong and stable for this datasetwith essentially negligile differences.\n",
    "\n",
    "Despite the similar results, I’m choosing LightGBM as the final model. It trains faster, has lower memory overhead, and integrates more smoothly with SHAP for real-time explainability in the Fairness Playground. Since responsiveness and interpretability are core goals of the app, LightGBM offers a cleaner user experience without sacrificing predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762262f3",
   "metadata": {},
   "source": [
    "### Training the Lightgb, on the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01a06f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1116, number of negative: 14019\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 907\n",
      "[LightGBM] [Info] Number of data points in the train set: 15135, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Final model trained on full training set\n"
     ]
    }
   ],
   "source": [
    "# Final LightGBM model (same settings as CV)\n",
    "final_lgb = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train on full training data\n",
    "final_lgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Final model trained on full training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c66cd2",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b87ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST SET PERFORMANCE\n",
      "======================================================================\n",
      "ROC-AUC: 0.958\n",
      "Precision: 0.485\n",
      "Recall: 0.785\n",
      "F1 Score: 0.599\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      3505\n",
      "           1       0.48      0.78      0.60       279\n",
      "\n",
      "    accuracy                           0.92      3784\n",
      "   macro avg       0.73      0.86      0.78      3784\n",
      "weighted avg       0.95      0.92      0.93      3784\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3272  233]\n",
      " [  60  219]]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_proba_test = final_lgb.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = final_lgb.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_test):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_test):.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b645645",
   "metadata": {},
   "source": [
    "Interpreting the Model’s Test Performance\n",
    "\n",
    "The final LightGBM model performs well on the test set. The ROC-AUC is 0.958, which means the model is very good at separating hospitalized vs. non-hospitalized individuals. The model also catches most of the people who actually were hospitalized with a recall for the positive class as 0.785. Precision is lower at 0.485, which is expected given how rare hospitalization is, but the F1-score (0.599) shows the model is balancing things reasonably well.\n",
    "\n",
    "Looking at the confusion matrix, the model correctly identifies 219 out of 279 hospitalized cases, while keeping false positives at a manageable level. Overall accuracy is about 92%, which lines up with the rest of the metrics.\n",
    "\n",
    "\n",
    "Overall, this level of performance is good enough for moving into explainability and building my fairness playground. A weak or noisy model would have made it hard to trust any fairness patterns, since differences across demographic groups would have just come from randomness. However here, the model is clearly learning real signals from the data, and it generalizes well.\n",
    "\n",
    "That means when I start showing SHAP explanations or let users tweak demographic attributes in the Fairness Playground, the changes in predictions will be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecace75",
   "metadata": {},
   "source": [
    "### Storing everythign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc108d",
   "metadata": {},
   "source": [
    "For fairness and explainability work, I also need the original demographic variables (age, sex, race/ethnicity, poverty level, insurance coverage, etc.). These are essential for checking whether the model behaves differently across groups, but they don’t belong inside the modeling matrix after one-hot encoding and leakage removal.\n",
    "\n",
    "So here, I extract a clean subset of the dataset containing only the human-readable demographic attributes plus person_id, and save it as df_meta. This makes it much easier in the fairness notebook to merge predictions back with the correct demographic information, without trying to reconstruct categories from dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efac8507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "person_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race_ethnicity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hispanic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "poverty_category",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "insurance_coverage",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family_income",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "self_rated_health",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "self_rated_mental_health",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "19355de9-b6eb-4cc2-a134-c443085afd7a",
       "rows": [
        [
         "0",
         "2790002101",
         "58",
         "2",
         "3",
         "2",
         "5",
         "1",
         "130700",
         "4",
         "3"
        ],
        [
         "1",
         "2790002102",
         "27",
         "1",
         "3",
         "2",
         "5",
         "1",
         "130700",
         "2",
         "2"
        ],
        [
         "2",
         "2790004101",
         "49",
         "2",
         "2",
         "2",
         "5",
         "1",
         "87000",
         "1",
         "1"
        ],
        [
         "3",
         "2790006101",
         "75",
         "2",
         "2",
         "2",
         "4",
         "2",
         "38000",
         "2",
         "2"
        ],
        [
         "4",
         "2790006102",
         "23",
         "1",
         "2",
         "2",
         "4",
         "2",
         "38000",
         "2",
         "2"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>poverty_category</th>\n",
       "      <th>insurance_coverage</th>\n",
       "      <th>family_income</th>\n",
       "      <th>self_rated_health</th>\n",
       "      <th>self_rated_mental_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2790002101</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>130700</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2790002102</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>130700</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2790004101</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790006101</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>38000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2790006102</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>38000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_id  age  sex  race_ethnicity  hispanic  poverty_category  \\\n",
       "0  2790002101   58    2               3         2                 5   \n",
       "1  2790002102   27    1               3         2                 5   \n",
       "2  2790004101   49    2               2         2                 5   \n",
       "3  2790006101   75    2               2         2                 4   \n",
       "4  2790006102   23    1               2         2                 4   \n",
       "\n",
       "   insurance_coverage  family_income self_rated_health  \\\n",
       "0                   1         130700                 4   \n",
       "1                   1         130700                 2   \n",
       "2                   1          87000                 1   \n",
       "3                   2          38000                 2   \n",
       "4                   2          38000                 2   \n",
       "\n",
       "  self_rated_mental_health  \n",
       "0                        3  \n",
       "1                        2  \n",
       "2                        1  \n",
       "3                        2  \n",
       "4                        2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAVE df_meta (demographic attributes only)\n",
    "\n",
    "meta_cols = [\n",
    "    \"person_id\",\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"race_ethnicity\",\n",
    "    \"hispanic\",\n",
    "    \"poverty_category\",\n",
    "    \"insurance_coverage\",\n",
    "    \"family_income\",\n",
    "    \"self_rated_health\",\n",
    "    \"self_rated_mental_health\",\n",
    "]\n",
    "\n",
    "df_meta = df_pd[meta_cols].copy()\n",
    "\n",
    "display(df_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f8ef0",
   "metadata": {},
   "source": [
    "In short df_meta will help me keep the original sensitive attributes separate from the modeling data, making fairness analysis simpler, safer, and more transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41bbd3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created artifacts directory: fairness_artifacts\n"
     ]
    }
   ],
   "source": [
    "# Creating a folder to store artifacts\n",
    "artifacts_dir = pathlib.Path(\"fairness_artifacts\")\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Created artifacts directory: {artifacts_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edb096d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata and IDs\n"
     ]
    }
   ],
   "source": [
    "# Saving the attribute table\n",
    "df_meta.to_parquet(artifacts_dir / \"df_meta.parquet\", index=False)\n",
    "ids_train.to_frame(name=\"person_id\").to_parquet(\n",
    "    artifacts_dir / \"ids_train.parquet\", index=False\n",
    ")\n",
    "ids_test.to_frame(name=\"person_id\").to_parquet(\n",
    "    artifacts_dir / \"ids_test.parquet\", index=False\n",
    ")\n",
    "\n",
    "print(\"Saved metadata and IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e598ac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train/test features\n"
     ]
    }
   ],
   "source": [
    "# Saving train/test feature matrices as Parquet\n",
    "X_train_path = artifacts_dir / \"X_train.parquet\"\n",
    "X_test_path = artifacts_dir / \"X_test.parquet\"\n",
    "\n",
    "X_train.to_parquet(X_train_path, index=False)\n",
    "X_test.to_parquet(X_test_path, index=False)\n",
    "\n",
    "print(\"Saved train/test features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb0e5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train/test targets\n"
     ]
    }
   ],
   "source": [
    "# Saving train/test targets as Parquet\n",
    "# Converting train/test targets to df to ensure clean schema\n",
    "y_train_path = artifacts_dir / \"y_train.parquet\"\n",
    "y_test_path = artifacts_dir / \"y_test.parquet\"\n",
    "\n",
    "y_train.to_frame(name=\"hospitalized\").to_parquet(y_train_path, index=False)\n",
    "y_test.to_frame(name=\"hospitalized\").to_parquet(y_test_path, index=False)\n",
    "\n",
    "print(\"Saved train/test targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3957447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "# Saving the trained LightGBM model\n",
    "model_path = artifacts_dir / \"final_lightgbm_model.pkl\"\n",
    "joblib.dump(final_lgb, model_path)\n",
    "\n",
    "print(\"Saved trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87869d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n",
      "Directory: fairness_artifacts\n",
      "\n",
      "Saved files:\n",
      "X_train: fairness_artifacts/X_train.parquet\n",
      "X_test: fairness_artifacts/X_test.parquet\n",
      "y_train: fairness_artifacts/y_train.parquet\n",
      "y_test: fairness_artifacts/y_test.parquet\n",
      "df_meta: fairness_artifacts/df_meta.parquet\n",
      "ids_train: fairness_artifacts/ids_train.parquet\n",
      "ids_test: fairness_artifacts/ids_test.parquet\n",
      "model: fairness_artifacts/final_lightgbm_model.pkl\n",
      "Data cleaning and modeling complete!\n",
      "Ready to proceed to fairness analysis (notebook 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved\")\n",
    "print(f\"Directory: {artifacts_dir}\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"X_train: {X_train_path}\")\n",
    "print(f\"X_test: {X_test_path}\")\n",
    "print(f\"y_train: {y_train_path}\")\n",
    "print(f\"y_test: {y_test_path}\")\n",
    "print(f\"df_meta: {artifacts_dir / 'df_meta.parquet'}\")\n",
    "print(f\"ids_train: {artifacts_dir / 'ids_train.parquet'}\")\n",
    "print(f\"ids_test: {artifacts_dir / 'ids_test.parquet'}\")\n",
    "print(f\"model: {model_path}\")\n",
    "\n",
    "print(\"Data cleaning and modeling complete!\")\n",
    "print(\"Ready to proceed to fairness analysis (notebook 2)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
