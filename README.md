# Healthcare Prediction Model with Explainable AI

This project predicts hospitalization risk using the MEPS (Medical Expenditure Panel Survey) dataset. I built a LightGBM model and created an interactive Streamlit app to explore predictions and understand what drives them. The main focus is on explainability - making it clear why the model makes certain predictions and how different factors affect risk.

## What This Project Does

I trained a model to predict whether someone will be hospitalized based on their demographics, socioeconomic status, and health conditions. The model uses LightGBM (a gradient boosting algorithm) and I integrated SHAP explanations so you can see exactly which features are driving each prediction.

### Files

1. **`1_analysis.ipynb`** - My main notebook where I did all the data cleaning, model training, and analysis
2. **`app.py`** - The Streamlit web app I built to interact with the model (see acknowledgments below)

## Dataset

I used the **MEPS 2023 Full Year Consolidated Data File (PUF Number: HC251)** from the Medical Expenditure Panel Survey. MEPS is a great dataset for healthcare research because it tracks people's medical expenses and health status over time.

- **Official Source**: [MEPS Website](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files.jsp)

The data includes:
- Demographics: age, sex, race/ethnicity
- Socioeconomic stuff: income, education, poverty level, region
- Health status: chronic conditions (hypertension, diabetes, asthma), smoking status
- Insurance coverage
- Healthcare utilization: inpatient expenditures (I used this to create the target variable - whether someone was hospitalized)

## Installation

You'll need Python 3.8 or higher. Then just:

1. Clone or download this repo

2. Install the packages:
```bash
pip install -r requirements.txt
```

Main packages you'll need:
- `streamlit` - For the web app
- `pandas`, `numpy`, `polars` - Data processing (polars is fast!)
- `lightgbm` - The model I used
- `shap` - For explainability
- `scikit-learn` - ML utilities
- `plotly`, `matplotlib` - Plotting
- `joblib` - Saving/loading models
- `openpyxl` - Reading Excel files

## Usage

### Running the Analysis Notebook

1. Make sure the Excel file `h251.xlsx` is in the `data/meps_2023/` directory (it should already be there if you cloned the repo)

2. Open `1_analysis.ipynb` in Jupyter Notebook or JupyterLab

3. The notebook walks through:
   - Loading and cleaning the MEPS data (handling those weird negative codes they use for missing values)
   - Feature engineering - renaming variables, one-hot encoding, creating the target variable
   - Model training - I compared LightGBM and XGBoost, LightGBM won
   - Evaluation - ROC-AUC, precision, recall, all that good stuff
   - Explainability - SHAP values to understand what the model is doing
   - Exporting everything needed for the Streamlit app

4. Run all cells to train the model and generate all the artifacts

**Note**: The notebook expects the data file at `./data/meps_2023/h251.xlsx`. Make sure this file exists before running the notebook.

### Running the Streamlit App

Just run:
```bash
streamlit run app.py
```

It'll open in your browser automatically.

## App Features

The app lets you play around with the model interactively:

### Step 1: Model Prediction
Use the sidebar to set patient characteristics, then see:
- Predicted hospitalization risk as a percentage
- Risk category (Low/Medium/High)
- Binary prediction (Hospitalized/Not Hospitalized) based on a threshold you can adjust

### Step 2: Local SHAP Explanation
- **SHAP Waterfall Plot**: Shows how each feature pushes the prediction up or down
- **Top Features**: The 10 most important features for this specific prediction
- **Summary**: A quick text explanation of what's driving the risk

### Step 3: What If? Analysis
Change features like insurance type, age, or poverty category and see how the prediction changes in real-time. Useful for understanding how different factors affect risk.

### Step 4: ICE Curve - Age Effect
An interactive plot showing how risk changes as age increases (keeping everything else constant). There's a line marking the current patient's age so you can see where they fall on the curve.

## File Structure

```
.
├── 1_analysis.ipynb          # Main analysis notebook
├── app.py                     # Streamlit web application
├── requirements.txt           # Python dependencies
├── README.md                  # This file
│
├── fairness_artifacts/        # Model and training data (generated by notebook)
│   ├── final_lightgbm_model.pkl
│   ├── X_train.parquet
│   ├── X_test.parquet
│   ├── y_train.parquet
│   └── y_test.parquet
│
└── fairness_results/          # Pre-computed results (generated by notebook)
    ├── shap_explainer.pkl
    └── df_fair_with_shap.parquet
```

## Model Details

### Algorithm
I used **LightGBM** after comparing it with XGBoost. LightGBM performed slightly better (ROC-AUC ~0.74 vs 0.72) and trains faster. I used stratified 5-fold cross-validation to make sure each fold had a good balance of hospitalized vs non-hospitalized cases.

### Target Variable
I created a binary `hospitalized` variable: 1 if someone had any inpatient expenditures > $0, 0 otherwise. This comes from the `inpatient_expenditures` field in the MEPS data.

### Features
The model uses about 50 features:
- **Numeric**: age, education_years, family_income, years_in_us
- **Categorical** (one-hot encoded): sex, race/ethnicity, poverty category, insurance coverage, region, chronic conditions, smoking status

## Explainability

I used **SHAP (SHapley Additive exPlanations)** to understand what the model is doing:

- **Global Importance**: Which features matter most overall (age is by far the biggest predictor)
- **Local Explanations**: For each individual prediction, which features pushed it up or down
- **Dependence Plots**: How specific features affect predictions across their value ranges

## Technical Notes

- The app uses Streamlit's caching to avoid reloading the model every time
- Feature vectors have to match the exact order the model expects (this caused me some headaches!)
- SHAP values are computed on-the-fly for real-time explanations
- Missing values are handled with median imputation for numeric features

## Acknowledgments

**Important Note**: I used ChatGPT-5 (via Cursor) to help me build the Streamlit app code (`app.py`). The app structure, UI components, and Streamlit-specific code were developed with AI assistance. However, **all of the analysis, model training, feature engineering, interpretations, and insights in the notebook are entirely my own work**. The model choices, evaluation approach, SHAP analysis, and all conclusions are based on my own analysis of the data.

## References

- **MEPS Dataset**: [AHRQ MEPS Website](https://meps.ahrq.gov/mepsweb/)
- **Model Approach**: Based on research showing gradient boosting effectiveness for healthcare tabular data
- **SHAP Documentation**: [SHAP GitHub](https://github.com/slundberg/shap)

## License

This project is for educational/research purposes. MEPS data usage should comply with AHRQ terms of use.
